"""Infer ASR output with BERT-based NER model and calculate SLUE scores"""

import json

from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline
from datasets import load_dataset
from loguru import logger
import fire


from slue import get_slue_format, get_ner_scores


def prepare_dataset():
    """Prepare the dataset for evaluation
    Return:
        dataset: the dataset for evaluation"""
    logger.info("Loading dataset")
    dataset = load_dataset("yuufong/vietmed_asr_v3")
    return dataset


def load_pipeline(model_path):
    """Load the BERT-based NER model
    Args:
        model_path: the path to the model
    Return:
        pipe: the pipeline for NER
        original_model: the original model name"""
    logger.info("Loading pipeline")
    model = AutoModelForTokenClassification.from_pretrained(model_path).to("cuda")
    original_model = json.load(open(f"{model_path}/config.json"))["_name_or_path"]
    tokenizer = AutoTokenizer.from_pretrained(original_model)
    pipe = pipeline(
        "ner",
        model=model,
        tokenizer=tokenizer,
        aggregation_strategy=None,
        batch_size=64,
    )
    return pipe, original_model


def merge_entities(entities):
    """Merge the entities with the same start or end
    Args:
        entities: the list of entities
    Return:
        merged_entities: the list of merged entities"""
    merged_entities = []
    current_entity = {}

    for entity in entities:
        # the next entity is the continuation of the current entity
        if current_entity and current_entity["end"] == entity["start"]:
            # Merge with the current entity
            current_entity["end"] = entity["end"]
            if entity["score"] > current_entity["score"]:
                current_entity["entity"] = entity["entity"]
                current_entity["score"] = entity["score"]
        # the next entity has the same start as the current entity
        elif current_entity and current_entity["start"] == entity["start"]:
            current_entity["start"] = entity["start"]
            if entity["score"] > current_entity["score"]:
                current_entity["entity"] = entity["entity"]
                current_entity["score"] = entity["score"]
        # the next entity has the same end as the current entity
        elif current_entity and current_entity["end"] == entity["end"]:
            current_entity["end"] = entity["end"]
            if entity["score"] > current_entity["score"]:
                current_entity["entity"] = entity["entity"]
                current_entity["score"] = entity["score"]
        elif entity["word"] == "‚ñÅ":  # skip the special token
            continue
        else:
            # Add the current entity to the list and start a new one
            if current_entity:
                merged_entities.append(current_entity["entity"])
            current_entity = entity

    # Add the last entity
    if current_entity:
        merged_entities.append(current_entity["entity"])

    return merged_entities


def cal_single_ds_ret(pipe, ds):
    """Calculate the SLUE scores for a single dataset
    Args:
        pipe: the pipeline for NER
        ds: the dataset
    Return:
        scores: the SLUE scores
        dummy_scores: the SLUE scores with dummy entities"""

    # Join list of words that are generated by the ASR model into a single string
    all_hyp_sequence = [" ".join(ds[i]["hyp"]) for i in range(len(ds))]
    # Join list of ground truth words into a single string
    all_gt = [get_slue_format(ds[i]["gt"], ds[i]["onehot_gt"]) for i in range(len(ds))]
    # Join list of ground truth words into a single string with dummy entities
    all_gt_dummy = [
        get_slue_format(ds[i]["gt"], ds[i]["onehot_gt"], use_dummy=True)
        for i in range(len(ds))
    ]

    # Get the predictions from the NER model on the ASR output
    all_predictions = pipe(all_hyp_sequence)
    # Merge the entities with the same start or end
    all_pred_tags = [merge_entities(predictions) for predictions in all_predictions]

    # Check if the number of sentences is equal
    assert (
        len(all_hyp_sequence) == len(all_gt) == len(all_pred_tags)
    ), "Number of sentences should be equal"

    # Join list of predicted words into a single string
    all_hyp = [get_slue_format(ds[i]["hyp"], all_pred_tags[i]) for i in range(len(ds))]

    # Join list of predicted words into a single string with dummy entities
    all_hyp_dummy = [
        get_slue_format(ds[i]["hyp"], all_pred_tags[i], use_dummy=True)
        for i in range(len(ds))
    ]

    # Calculate the SLUE scores
    scores = get_ner_scores(all_gt, all_hyp)
    # Calculate the SLUE scores with dummy entities
    dummy_scores = get_ner_scores(all_gt_dummy, all_hyp_dummy)

    return scores, dummy_scores


def get_slue_results(model_path):
    """Get the SLUE scores for each of ASR output
    Args:
        model_path: the path to the model
    Return:
        results: the SLUE scores for each of ASR output"""
    dataset = prepare_dataset()
    pipe, original_model = load_pipeline(model_path)
    results = {}
    for ds in dataset:
        sub_ds_name = str(ds)
        logger.info(f"Calculating scores for {sub_ds_name}")
        scores, dummy_scores = cal_single_ds_ret(pipe, dataset[sub_ds_name])
        results[sub_ds_name] = {"slue_score": scores, "dummy_score": dummy_scores}

        with open(f"asr_slue_output/{original_model}_{sub_ds_name}.json", "w") as f:
            json.dump(results, f, indent=4)


if __name__ == "__main__":
    fire.Fire(get_slue_results)
